{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "We will be focusing on XGBoost, since it achieved the best score in the eda steps.\n",
    "Possibly the best solution would involve a combination of some neural network, with XGBoost \n",
    "and/or LightGBM. More details on the steps and decisions can be found in the data_eda.ipynb notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import xgboost as xgb\n",
    "import notebook_utils as nu \n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads Data and Separates into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [x for x in data.columns if (x not in ['ID_code', 'target'])]\n",
    "\n",
    "X = data[x_cols]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38762     0\n",
       "76883     0\n",
       "2018      0\n",
       "133899    0\n",
       "170373    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38762</th>\n",
       "      <td>12.6508</td>\n",
       "      <td>-1.4518</td>\n",
       "      <td>4.9398</td>\n",
       "      <td>9.4263</td>\n",
       "      <td>11.3132</td>\n",
       "      <td>-3.2654</td>\n",
       "      <td>5.3040</td>\n",
       "      <td>20.0105</td>\n",
       "      <td>-0.5506</td>\n",
       "      <td>7.4902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>10.1718</td>\n",
       "      <td>1.8558</td>\n",
       "      <td>12.2295</td>\n",
       "      <td>22.8003</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>8.9432</td>\n",
       "      <td>10.7889</td>\n",
       "      <td>-15.1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76883</th>\n",
       "      <td>8.8434</td>\n",
       "      <td>-5.0525</td>\n",
       "      <td>5.8053</td>\n",
       "      <td>2.5540</td>\n",
       "      <td>9.7131</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>5.3080</td>\n",
       "      <td>14.4369</td>\n",
       "      <td>4.9028</td>\n",
       "      <td>6.9503</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2870</td>\n",
       "      <td>10.8789</td>\n",
       "      <td>2.6776</td>\n",
       "      <td>-5.2744</td>\n",
       "      <td>19.9168</td>\n",
       "      <td>-0.5264</td>\n",
       "      <td>-3.4889</td>\n",
       "      <td>9.4107</td>\n",
       "      <td>10.8898</td>\n",
       "      <td>6.6960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>5.8905</td>\n",
       "      <td>3.8340</td>\n",
       "      <td>7.7051</td>\n",
       "      <td>8.8097</td>\n",
       "      <td>12.6723</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>4.1572</td>\n",
       "      <td>14.7936</td>\n",
       "      <td>-0.2814</td>\n",
       "      <td>9.8768</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1241</td>\n",
       "      <td>4.4696</td>\n",
       "      <td>5.0724</td>\n",
       "      <td>1.5313</td>\n",
       "      <td>17.1286</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.8431</td>\n",
       "      <td>8.8373</td>\n",
       "      <td>16.0513</td>\n",
       "      <td>-11.9798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133899</th>\n",
       "      <td>8.2786</td>\n",
       "      <td>5.8034</td>\n",
       "      <td>13.2013</td>\n",
       "      <td>8.9956</td>\n",
       "      <td>13.5608</td>\n",
       "      <td>-10.0445</td>\n",
       "      <td>5.1545</td>\n",
       "      <td>16.3067</td>\n",
       "      <td>-3.5246</td>\n",
       "      <td>10.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>14.6195</td>\n",
       "      <td>3.0610</td>\n",
       "      <td>-5.9456</td>\n",
       "      <td>15.4801</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>-1.0892</td>\n",
       "      <td>7.4688</td>\n",
       "      <td>16.2685</td>\n",
       "      <td>-10.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170373</th>\n",
       "      <td>7.3882</td>\n",
       "      <td>6.3704</td>\n",
       "      <td>9.9413</td>\n",
       "      <td>7.9744</td>\n",
       "      <td>11.6259</td>\n",
       "      <td>-8.7820</td>\n",
       "      <td>4.4755</td>\n",
       "      <td>17.7317</td>\n",
       "      <td>3.7531</td>\n",
       "      <td>8.8027</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1395</td>\n",
       "      <td>5.5115</td>\n",
       "      <td>3.3208</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>19.2325</td>\n",
       "      <td>-2.2717</td>\n",
       "      <td>7.2787</td>\n",
       "      <td>9.0987</td>\n",
       "      <td>15.9157</td>\n",
       "      <td>-17.2046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "38762   12.6508 -1.4518   4.9398  9.4263  11.3132  -3.2654  5.3040  20.0105   \n",
       "76883    8.8434 -5.0525   5.8053  2.5540   9.7131   1.8681  5.3080  14.4369   \n",
       "2018     5.8905  3.8340   7.7051  8.8097  12.6723   0.0678  4.1572  14.7936   \n",
       "133899   8.2786  5.8034  13.2013  8.9956  13.5608 -10.0445  5.1545  16.3067   \n",
       "170373   7.3882  6.3704   9.9413  7.9744  11.6259  -8.7820  4.4755  17.7317   \n",
       "\n",
       "         var_8    var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "38762  -0.5506   7.4902  ...   0.9493  10.1718   1.8558  12.2295  22.8003   \n",
       "76883   4.9028   6.9503  ...   5.2870  10.8789   2.6776  -5.2744  19.9168   \n",
       "2018   -0.2814   9.8768  ...   4.1241   4.4696   5.0724   1.5313  17.1286   \n",
       "133899 -3.5246  10.0120  ...   0.7748  14.6195   3.0610  -5.9456  15.4801   \n",
       "170373  3.7531   8.8027  ...   9.1395   5.5115   3.3208   0.3378  19.2325   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "38762    0.1811   1.0184   8.9432  10.7889 -15.1560  \n",
       "76883   -0.5264  -3.4889   9.4107  10.8898   6.6960  \n",
       "2018     0.9120   0.8431   8.8373  16.0513 -11.9798  \n",
       "133899   0.2584  -1.0892   7.4688  16.2685 -10.2297  \n",
       "170373  -2.2717   7.2787   9.0987  15.9157 -17.2046  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_indexes = y_train.index[y_train == 0].tolist()\n",
    "df1_indexes = y_train.index[y_train == 1].tolist()\n",
    "\n",
    "X_train_0 = X_train.loc[df0_indexes]\n",
    "y_train_0 = y_train.loc[df0_indexes]\n",
    "\n",
    "nr_df_0 = X_train_0.shape[0]\n",
    "\n",
    "X_train_1 = X_train.loc[df1_indexes]\n",
    "y_train_1 = y_train.loc[df1_indexes]\n",
    "\n",
    "n_samples = nr_df_0\n",
    "X_train_1, y_train_1 = resample(X_train_1, y_train_1, replace=True, n_samples=n_samples,random_state=random_state)\n",
    "\n",
    "X_train = pd.concat([X_train_0, X_train_1])\n",
    "y_train = pd.concat([y_train_0, y_train_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "      <td>323870.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.892665</td>\n",
       "      <td>-1.365485</td>\n",
       "      <td>10.910729</td>\n",
       "      <td>6.825571</td>\n",
       "      <td>11.097798</td>\n",
       "      <td>-4.748479</td>\n",
       "      <td>5.488130</td>\n",
       "      <td>16.542181</td>\n",
       "      <td>0.365201</td>\n",
       "      <td>7.501028</td>\n",
       "      <td>...</td>\n",
       "      <td>3.575732</td>\n",
       "      <td>7.623189</td>\n",
       "      <td>1.842769</td>\n",
       "      <td>3.236723</td>\n",
       "      <td>17.898590</td>\n",
       "      <td>-0.093978</td>\n",
       "      <td>2.473966</td>\n",
       "      <td>8.864975</td>\n",
       "      <td>15.659997</td>\n",
       "      <td>-2.963305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.150621</td>\n",
       "      <td>4.136830</td>\n",
       "      <td>2.740539</td>\n",
       "      <td>2.060147</td>\n",
       "      <td>1.638567</td>\n",
       "      <td>7.986068</td>\n",
       "      <td>0.896579</td>\n",
       "      <td>3.420468</td>\n",
       "      <td>3.333813</td>\n",
       "      <td>1.256785</td>\n",
       "      <td>...</td>\n",
       "      <td>4.688064</td>\n",
       "      <td>3.113859</td>\n",
       "      <td>1.484306</td>\n",
       "      <td>4.024613</td>\n",
       "      <td>3.165741</td>\n",
       "      <td>1.455688</td>\n",
       "      <td>5.496634</td>\n",
       "      <td>0.935680</td>\n",
       "      <td>3.123425</td>\n",
       "      <td>10.446711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.452800</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>3.970500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.559500</td>\n",
       "      <td>-4.533075</td>\n",
       "      <td>8.826400</td>\n",
       "      <td>5.271950</td>\n",
       "      <td>9.889500</td>\n",
       "      <td>-10.944625</td>\n",
       "      <td>4.819200</td>\n",
       "      <td>13.921600</td>\n",
       "      <td>-2.227200</td>\n",
       "      <td>6.551700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>5.270500</td>\n",
       "      <td>0.788700</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>15.529000</td>\n",
       "      <td>-1.150975</td>\n",
       "      <td>-1.765575</td>\n",
       "      <td>8.213500</td>\n",
       "      <td>13.573900</td>\n",
       "      <td>-10.790950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.726800</td>\n",
       "      <td>-1.338600</td>\n",
       "      <td>10.792000</td>\n",
       "      <td>6.864550</td>\n",
       "      <td>11.126000</td>\n",
       "      <td>-4.513600</td>\n",
       "      <td>5.477700</td>\n",
       "      <td>16.463800</td>\n",
       "      <td>0.479650</td>\n",
       "      <td>7.571600</td>\n",
       "      <td>...</td>\n",
       "      <td>3.557100</td>\n",
       "      <td>7.543400</td>\n",
       "      <td>1.790900</td>\n",
       "      <td>3.301000</td>\n",
       "      <td>17.858800</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>2.600900</td>\n",
       "      <td>8.846400</td>\n",
       "      <td>15.719500</td>\n",
       "      <td>-2.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.014100</td>\n",
       "      <td>1.646200</td>\n",
       "      <td>12.731000</td>\n",
       "      <td>8.352900</td>\n",
       "      <td>12.291100</td>\n",
       "      <td>1.223200</td>\n",
       "      <td>6.100500</td>\n",
       "      <td>19.082500</td>\n",
       "      <td>3.012400</td>\n",
       "      <td>8.524375</td>\n",
       "      <td>...</td>\n",
       "      <td>6.843400</td>\n",
       "      <td>9.718300</td>\n",
       "      <td>2.868500</td>\n",
       "      <td>6.140900</td>\n",
       "      <td>20.318400</td>\n",
       "      <td>0.892900</td>\n",
       "      <td>6.728000</td>\n",
       "      <td>9.562900</td>\n",
       "      <td>17.942875</td>\n",
       "      <td>5.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.355600</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>11.150600</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.684600</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               var_0          var_1          var_2          var_3  \\\n",
       "count  323870.000000  323870.000000  323870.000000  323870.000000   \n",
       "mean       10.892665      -1.365485      10.910729       6.825571   \n",
       "std         3.150621       4.136830       2.740539       2.060147   \n",
       "min         0.452800     -15.043400       2.117100      -0.040200   \n",
       "25%         8.559500      -4.533075       8.826400       5.271950   \n",
       "50%        10.726800      -1.338600      10.792000       6.864550   \n",
       "75%        13.014100       1.646200      12.731000       8.352900   \n",
       "max        20.315000      10.376800      19.353000      13.188300   \n",
       "\n",
       "               var_4          var_5          var_6          var_7  \\\n",
       "count  323870.000000  323870.000000  323870.000000  323870.000000   \n",
       "mean       11.097798      -4.748479       5.488130      16.542181   \n",
       "std         1.638567       7.986068       0.896579       3.420468   \n",
       "min         5.074800     -32.562600       2.347300       5.349700   \n",
       "25%         9.889500     -10.944625       4.819200      13.921600   \n",
       "50%        11.126000      -4.513600       5.477700      16.463800   \n",
       "75%        12.291100       1.223200       6.100500      19.082500   \n",
       "max        16.671400      17.251600       8.355600      27.691800   \n",
       "\n",
       "               var_8          var_9  ...        var_190        var_191  \\\n",
       "count  323870.000000  323870.000000  ...  323870.000000  323870.000000   \n",
       "mean        0.365201       7.501028  ...       3.575732       7.623189   \n",
       "std         3.333813       1.256785  ...       4.688064       3.113859   \n",
       "min       -10.505500       3.970500  ...     -14.093300      -2.691700   \n",
       "25%        -2.227200       6.551700  ...       0.167200       5.270500   \n",
       "50%         0.479650       7.571600  ...       3.557100       7.543400   \n",
       "75%         3.012400       8.524375  ...       6.843400       9.718300   \n",
       "max        10.151300      11.150600  ...      18.440900      16.684600   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  323870.000000  323870.000000  323870.000000  323870.000000   \n",
       "mean        1.842769       3.236723      17.898590      -0.093978   \n",
       "std         1.484306       4.024613       3.165741       1.455688   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.788700       0.497800      15.529000      -1.150975   \n",
       "50%         1.790900       3.301000      17.858800      -0.135000   \n",
       "75%         2.868500       6.140900      20.318400       0.892900   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  323870.000000  323870.000000  323870.000000  323870.000000  \n",
       "mean        2.473966       8.864975      15.659997      -2.963305  \n",
       "std         5.496634       0.935680       3.123425      10.446711  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.765575       8.213500      13.573900     -10.790950  \n",
       "50%         2.600900       8.846400      15.719500      -2.466400  \n",
       "75%         6.728000       9.562900      17.942875       5.249200  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    323870.000000\n",
       "mean          0.500000\n",
       "std           0.500001\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.500000\n",
       "75%           1.000000\n",
       "max           1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Train Single XGBoost Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'learning_rate': 0.3, # default\n",
    "    'max_depth': 6, # default\n",
    "    'min_child_weight': 1, # default\n",
    "#     'subsample': 0.75,\n",
    "#     'colsample_bytree': 0.75,\n",
    "    'random_state': random_state\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ffreis/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:19:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(learning_rate=hyperparameters['learning_rate'],\n",
    "                              n_jobs=-1,\n",
    "                              max_depth=hyperparameters['max_depth'],\n",
    "                              min_child_weight=hyperparameters['min_child_weight'],\n",
    "#                               subsample=hyperparameters['subsample'],\n",
    "#                               colsample_bytree=hyperparameters['colsample_bytree'],\n",
    "                              objective='binary:logistic',\n",
    "                              random_state=random_state,\n",
    "                              verbosity=1\n",
    "                              )\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary:logistic', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'gpu_id': -1, 'interaction_constraints': '', 'learning_rate': 0.3, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 1, 'monotone_constraints': '()', 'n_jobs': -1, 'num_parallel_tree': 1, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None...\n",
       "                      'n_jobs': -1, 'num_parallel_tree': 1,\n",
       "                      'objective': 'binary:logistic', 'random_state': 42,\n",
       "                      'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1,\n",
       "                      'subsample': 1, 'tree_method': 'exact',\n",
       "                      'validate_parameters': 1, 'verbosity': 1},\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              use_label_encoder=True, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xgb_model.get_xgb_params())\n",
    "xgb.XGBClassifier(params = xgb_model.get_xgb_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Evaluate the Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.86595\n",
      "gini score: 0.5079081009615076\n",
      "f1 score: 0.48193236714975846\n",
      "precision score: 0.3968809675366009\n",
      "recall score: 0.6133792424987703\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "y_true = np.array(y_test)\n",
    "\n",
    "scores = nu.get_scores(y_true, y_pred)\n",
    "nu.print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.joblib.dat']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb_model, \"xgb_model.joblib.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Tests if model was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = pickle.load(open(\"xgb_model.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.86595\n",
      "gini score: 0.5079081009615076\n",
      "f1 score: 0.48193236714975846\n",
      "precision score: 0.3968809675366009\n",
      "recall score: 0.6133792424987703\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "y_true = np.array(y_test)\n",
    "\n",
    "scores = nu.get_scores(y_true, y_pred)\n",
    "nu.print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) First Hyperparameter Selection/Tuning\n",
    "TODO: make GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-326acb4f6f3b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-326acb4f6f3b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    'learning_rate': [0.01, 0.03, 0.1],\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'learning_rate': [0.01, 0.03, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10, 15],\n",
    "        'min_child_weight': [1, 3, 5, 10],\n",
    "        'subsample': [0.3, 0.5, 0.75, 1],\n",
    "        'colsample_bytree': [0.3, 0.5, 0.75, 1],\n",
    "        'n_estimators' : [50, 100, 200, 500, 1000],\n",
    "        'objective': ['reg:squarederror']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Second Hyperparameter Selection\n",
    "TODO\n",
    "The second iteration is made based on the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
